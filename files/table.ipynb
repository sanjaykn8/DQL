{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2f0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust paths to your saved pickles\n",
    "reward_files = sorted(Path(\"checkpoint_data\").glob(\"total_rewards_list_*.pkl\"))\n",
    "loss_files = sorted(Path(\"checkpoint_data\").glob(\"total_loss_list_*.pkl\"))\n",
    "\n",
    "# load latest or specific\n",
    "def load_latest(files):\n",
    "    if not files:\n",
    "        raise RuntimeError(\"No files found\")\n",
    "    with open(files[-1], \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "rewards = load_latest(reward_files)  # list of lists (episodes grouped)\n",
    "losses = load_latest(loss_files)     # list of lists\n",
    "\n",
    "# flatten into per-episode average if needed\n",
    "flat_rewards = [np.mean(batch) if isinstance(batch, (list,tuple)) and batch else 0 for batch in rewards]\n",
    "smoothed = np.convolve(flat_rewards, np.ones(50)/50, mode='valid')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(len(smoothed)), smoothed, label=\"Smoothed Reward (win=50)\")\n",
    "plt.title(\"Training Reward Curve (Smoothed)\")\n",
    "plt.xlabel(\"Checkpoints\")\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Imgs/reward_curve_smoothed.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Loss plot: convert each stored losses list to mean per checkpoint\n",
    "mean_losses = [np.mean(batch) if batch else 0 for batch in losses]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(mean_losses, label=\"Mean Huber Loss\")\n",
    "plt.title(\"TD-Loss (Huber) vs Iterations\")\n",
    "plt.xlabel(\"Checkpoint Index\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Imgs/t d_loss_iterations.png\", dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ded2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 1686180\n",
      "network.0.weight torch.Size([32, 4, 8, 8]) 8192\n",
      "network.0.bias torch.Size([32]) 32\n",
      "network.2.weight torch.Size([64, 32, 4, 4]) 32768\n",
      "network.2.bias torch.Size([64]) 64\n",
      "network.4.weight torch.Size([64, 64, 3, 3]) 36864\n",
      "network.4.bias torch.Size([64]) 64\n",
      "network.7.weight torch.Size([512, 3136]) 1605632\n",
      "network.7.bias torch.Size([512]) 512\n",
      "network.9.weight torch.Size([4, 512]) 2048\n",
      "network.9.bias torch.Size([4]) 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, nb_actions):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(4,32,8,stride=4), nn.ReLU(),\n",
    "            nn.Conv2d(32,64,4,stride=2), nn.ReLU(),\n",
    "            nn.Conv2d(64,64,3,stride=1), nn.ReLU(),\n",
    "            nn.Flatten(), nn.Linear(3136,512), nn.ReLU(),\n",
    "            nn.Linear(512, nb_actions),\n",
    "        )\n",
    "    def forward(self,x): return self.network(x)\n",
    "\n",
    "def param_table(nb_actions=4):\n",
    "    m = DQN(nb_actions)\n",
    "    total = sum(p.numel() for p in m.parameters())\n",
    "    print(\"Total params:\", total)\n",
    "    for name, p in m.named_parameters():\n",
    "        print(name, p.shape, p.numel())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    param_table(nb_actions=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a821f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.atari_wrappers import MaxAndSkipEnv\n",
    "from gymnasium.wrappers import ResizeObservation, GrayscaleObservation, FrameStackObservation\n",
    "import matplotlib.pyplot as plt\n",
    "import ale_py\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "env = gym.make(\"ALE/Breakout-v5\")\n",
    "env = ResizeObservation(env, (84,84))\n",
    "env = GrayscaleObservation(env)\n",
    "env = FrameStackObservation(env, 4)\n",
    "env = MaxAndSkipEnv(env, skip=4)\n",
    "\n",
    "obs, _ = env.reset()\n",
    "plt.figure(figsize=(10,3))\n",
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.imshow(obs[i], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Preprocessed Frame Stack (84×84×4)\")\n",
    "plt.savefig(\"Fig4_1_preprocessing_pipeline.png\", dpi=300)\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
